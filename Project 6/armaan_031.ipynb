{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901d4dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Imputation Script Starting ---\n",
      "\n",
      "--- Step 1: Loading the Dataset ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Pclass', 'SibSp', 'Parch', 'Fare', 'Age'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m df = sns.load_dataset(\u001b[33m'\u001b[39m\u001b[33mtitanic\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# We'll just keep the columns we need for this example\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mFEATURES\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mTARGET\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOriginal Dataset (first 10 rows):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.head(\u001b[32m10\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mise/installs/python/3.13.7/lib/python3.13/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mise/installs/python/3.13.7/lib/python3.13/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/mise/installs/python/3.13.7/lib/python3.13/site-packages/pandas/core/indexes/base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['Pclass', 'SibSp', 'Parch', 'Fare', 'Age'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# --- Configuration ---\n",
    "# This is a raw CSV URL for the \"Ames Housing\" training data, a popular Kaggle dataset.\n",
    "DATA_URL = \"https://raw.githubusercontent.com/dataprofessor/data/master/house_price_train.csv\"\n",
    "\n",
    "# We will predict 'LotFrontage' (the target)\n",
    "# using these features.\n",
    "TARGET = 'LotFrontage'\n",
    "FEATURES = ['LotArea', 'OverallQual', 'YearBuilt']\n",
    "\n",
    "# Set pandas to display more info\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"--- Data Imputation Script Starting ---\")\n",
    "\n",
    "# --- Step 1: Load the Dataset ---\n",
    "print(f\"\\n--- Step 1: Loading Dataset from URL ---\\n{DATA_URL}\")\n",
    "try:\n",
    "    df = pd.read_csv(DATA_URL)\n",
    "    \n",
    "    # For this exercise, we'll only keep our feature and target columns\n",
    "    df = df[FEATURES + [TARGET]]\n",
    "    \n",
    "    print(\"\\nOriginal Dataset (first 10 rows):\")\n",
    "    print(df.head(10))\n",
    "    \n",
    "    print(\"\\nMissing values BEFORE imputation:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"-----------------------------------\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"Please check the DATA_URL or your internet connection.\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 2: Train Linear Regression Model ---\n",
    "print(f\"\\n--- Step 2: Training Model to Predict '{TARGET}' ---\")\n",
    "\n",
    "# Create the training set using only rows where 'LotFrontage' is NOT null\n",
    "df_train = df.dropna(subset=[TARGET])\n",
    "\n",
    "# Check if we have any data to train on\n",
    "if df_train.empty:\n",
    "    print(f\"Error: No complete rows found to train the model. Cannot proceed.\")\n",
    "else:\n",
    "    X_train = df_train[FEATURES]\n",
    "    y_train = df_train[TARGET]\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Model trained successfully using {FEATURES}.\")\n",
    "    print(f\"Model coefficients (for {FEATURES}): {model.coef_}\")\n",
    "    print(f\"Model intercept: {model.intercept_}\")\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "\n",
    "    # --- Step 3: Use Trained Model to Fill Missing Values ---\n",
    "    print(f\"\\n--- Step 3: Predicting and Filling Missing '{TARGET}' Values ---\")\n",
    "    \n",
    "    # Get all rows where 'LotFrontage' IS null\n",
    "    df_predict = df[df[TARGET].isnull()]\n",
    "    \n",
    "    # Check if there are any values to predict\n",
    "    if df_predict.empty:\n",
    "        print(\"No missing values found to predict.\")\n",
    "    else:\n",
    "        # Select the features for prediction\n",
    "        X_predict = df_predict[FEATURES]\n",
    "        \n",
    "        # Use the trained model to predict 'LotFrontage'\n",
    "        predicted_values = model.predict(X_predict)\n",
    "        \n",
    "        # Fill the missing values in the original dataframe\n",
    "        # We use .loc to safely assign the values back\n",
    "        df.loc[df[TARGET].isnull(), TARGET] = predicted_values\n",
    "        \n",
    "        print(f\"Successfully predicted and filled {len(predicted_values)} missing '{TARGET}' values.\")\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "\n",
    "    # --- Step 4: Display the Dataset After Filling ---\n",
    "    print(\"\\n--- Step 4: Displaying Final Dataset ---\")\n",
    "    \n",
    "    print(\"Dataset AFTER imputation (first 10 rows):\")\n",
    "    # Note rows 2, 7, and 9 (indices) which were 'NaN' are now filled.\n",
    "    print(df.head(10))\n",
    "    \n",
    "    print(\"\\nMissing values AFTER imputation:\")\n",
    "    # The 'LotFrontage' column should now show 0 missing values\n",
    "    print(df.isnull().sum())\n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"\\n--- Data Imputation Script Finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
